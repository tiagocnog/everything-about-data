{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA ANALYSIS process**\n",
    "\n",
    "#### **Ask**\n",
    "* Ask effective questions\n",
    "* Define the problem\n",
    "* Use structured thinking\n",
    "* Communicate with others\n",
    "\n",
    "#### **Prepare**\n",
    "* Undestand how data is generated and collected\n",
    "* Identify and use different data formats, types, and structures\n",
    "* Make sure data is unbiased and credible\n",
    "* Organize and protect data\n",
    "\n",
    "#### **Process**\n",
    "* Create and transform data\n",
    "* Maintain data integrity\n",
    "* Test data\n",
    "* Clean data\n",
    "* Verify and report on cleaning results\n",
    "\n",
    "#### **Analyze**\n",
    "* Use tools to format and transform data\n",
    "* Sort and filter data\n",
    "* Identify patterns and draw conclusions\n",
    "* Make predictions and recommendations\n",
    "* Make data-driven decisions\n",
    "\n",
    "#### **Share**\n",
    "* Understand visualization\n",
    "* Create effective visuals\n",
    "* Bring data to life\n",
    "* Use data storytelling\n",
    "* Communicate to help others understand results\n",
    "\n",
    "#### **Act**\n",
    "* Apply your insights\n",
    "* Solve problems\n",
    "* Make decisions\n",
    "* Create something new\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------\n",
    "## *TIPS*\n",
    "\n",
    "* Have methods for everything you do \n",
    "* Always document what you do\n",
    "* Manage expepectations\n",
    "* 2 minutes rule \n",
    "    - If some task can be done within 2 minutes, always do it.\n",
    "* Take time to understand the problem and plan the next steps\n",
    "* Always doublecheck your work\n",
    "* Mistakes will happen eventually\n",
    "    - Try to keep it cool and work through it \n",
    "* **Always formalize and or document dates, deliverables and deadlines. (SCOPE OF WORK)**\n",
    "------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scope of work\n",
    "\n",
    "**Data team:** (Team members)\n",
    "\n",
    "\n",
    "**Client/Sponsor/Stakeholders:** (Stakeholders)\n",
    "\n",
    "\n",
    "**Purpose:** Write a brief description of why this project is happenning. *Why is this project happening? What are the goals?* \n",
    "\n",
    "\n",
    "**Scope / Major Project Activities:** \n",
    "*What are the major parts of this project? List out the high-level steps, activities, or stages of the project, and give a brief description for each.*\n",
    "\n",
    "Activity | Description\n",
    "--- | ---\n",
    "activity_1 | description_1\n",
    "\n",
    "\n",
    "**This project does not include:**\n",
    "*Specify the things that this project isn‚Äôt responsible for doing (out of scope).*\n",
    "* Out of scope 1\n",
    "* Out of scope 2\n",
    "\n",
    "\n",
    "**Deliverables:** \n",
    "*A specific list of things that your project will deliver.*\n",
    "\n",
    "Deliverable | Description/ Details\n",
    "--- | ---\n",
    "deliverable_1 | description_1\n",
    "\n",
    "\n",
    "**Schedule Overview / Major Milestones:** \n",
    "*The expected schedule for the project. This can be defined by milestones (e.g. ‚Äúall data is cleaned and processed‚Äù), periods of time (‚ÄúWeek 1 / Week 2‚Äù), or other ways based on the needs of the project.*\n",
    "\n",
    "Milestone | Expected Completion Date* | Description/Details\n",
    "--- | --- | ---\n",
    "milestone_1 | date_1 | description_1\n",
    "\n",
    "*Estimated date for completion: This is my ‚Äúif all goes well and I have everything I need, this is when I‚Äôll be done‚Äù date.\n",
    "\n",
    "**Always manage expectations**\n",
    "\n",
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Ask**\n",
    "* Ask effective questions\n",
    "* Define the problem\n",
    "* Use structured thinking\n",
    "* Communicate with others\n",
    "\n",
    ".-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Collect**\n",
    "* Undestand how data is generated and collected\n",
    "* Identify and use different data formats, types, and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing data via connection with RDBMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the PostgreSQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the PostgreSQL server\n",
    "# connection = psycopg2.connect(\n",
    "#     host=\"localhost\",       # or your PostgreSQL server's IP address\n",
    "#     database=\"your_db_name\", # replace with your database name\n",
    "#     user=\"your_username\",    # replace with your database username\n",
    "#     password=\"your_password\" # replace with your database password\n",
    "# )\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "# Create a table\n",
    "# cursor.execute('''\n",
    "# CREATE TABLE IF NOT EXISTS users (\n",
    "#     id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "#     name VARCHAR(100),\n",
    "#     age INT\n",
    "# )\n",
    "# ''')\n",
    "\n",
    "# Commit the changes\n",
    "# connection.commit()\n",
    "\n",
    "# Insert data into the table\n",
    "# cursor.execute(\"INSERT INTO users (name, age) VALUES (%s, %s)\", (\"John Doe\", 30))\n",
    "\n",
    "# Commit the transaction\n",
    "# connection.commit()\n",
    "\n",
    "# Query data from the table\n",
    "# cursor.execute(\"SELECT * FROM users\")\n",
    "\n",
    "# Fetch all results\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# Print the results\n",
    "# for row in rows:\n",
    "#     print(row)\n",
    "\n",
    "# Close the cursor and connection\n",
    "# cursor.close()\n",
    "# connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to the MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the connection to MySQL\n",
    "# connection = mysql.connector.connect(\n",
    "#     host=\"localhost\",        # or your MySQL server's IP address\n",
    "#     database=\"your_db_name\", # replace with your database name\n",
    "#     user=\"your_username\",    # replace with your MySQL username\n",
    "#     password=\"your_password\" # replace with your MySQL password\n",
    "# )\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "# cursor = connection.cursor()\n",
    "\n",
    "\n",
    "# Close the cursor and connection\n",
    "# cursor.close()\n",
    "# connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put this on the .env file and use load_dotenv() to retrive\n",
    "# # Replace with your actual MongoDB credentials and database details\n",
    "# username = 'your_username'\n",
    "# password = 'your_password'\n",
    "# host = 'localhost'  # or remote MongoDB host\n",
    "# port = '27017'  # default port\n",
    "# database_name = 'your_database'  # database you want to connect to\n",
    "# auth_db = 'admin'  # database where credentials are stored (often 'admin')\n",
    "\n",
    "# # Create the connection string with authentication\n",
    "# connection_string = f'mongodb://{username}:{password}@{host}:{port}/{database_name}?authSource={auth_db}'\n",
    "\n",
    "# # Connect to MongoDB using the connection string\n",
    "# client = MongoClient(connection_string)\n",
    "\n",
    "# # Access the database\n",
    "# db = client[database_name]\n",
    "\n",
    "# # Check the connection by getting server status\n",
    "# try:\n",
    "#     # Attempt to retrieve the server status to verify the connection\n",
    "#     server_status = db.command(\"serverStatus\")\n",
    "#     print(\"Connection successful:\", server_status)\n",
    "# except Exception as e:\n",
    "#     print(\"Error connecting to MongoDB:\", e)\n",
    "\n",
    "# # Close the connection\n",
    "# client.close()\n",
    "\n",
    "# Check documentation if something is wrong:https://www.mongodb.com/resources/languages/python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to SAS using SASPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saspy\n",
    "# Find the configuration file (saspy.py) or create a new one if necessary.\n",
    "# Modify it with the connection details:\n",
    "# saspy.SAS_config_names = ['sas_config']\n",
    "\n",
    "# sas_config = {\n",
    "#     'sas_config': {\n",
    "#         'saspath': '/path/to/sas',\n",
    "#         'options': [\"-fullstimer\"],\n",
    "#         'encoding': 'latin1'\n",
    "#     }\n",
    "# }\n",
    "# Replace '/path/to/sas' with the actual path to your SAS executable\n",
    "\n",
    "# sas = saspy.SASsession(cfgname='sas_config')  # Use the configuration you set up\n",
    "# sas.submit(\"data test; input x; datalines; 1; 2; 3; run;\")  # Example SAS code\n",
    "# sas.saslib('test')  # Access the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting Python with AWS step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Boto3\n",
    "`pip install boto3`\n",
    "\n",
    "2. Set up AWS Credentials\n",
    "    * AWS CLI\n",
    "        * bash command: \n",
    "            - aws configure\n",
    "\n",
    "    * Manually Set AWS Credentials\n",
    "        * C:\\Users\\Name\\\\.aws\\credentials\n",
    "            - [default]\n",
    "            - aws_access_key_id = YOUR_ACCESS_KEY\n",
    "            - aws_secret_access_key = YOUR_SECRET_KEY\n",
    "    \n",
    "    * Environment Variables\n",
    "        * bash command: \n",
    "            - export AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY\n",
    "            - export AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY\n",
    "            - export AWS_DEFAULT_REGION=us-west-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env credentials\n",
    "load_dotenv()\n",
    "\n",
    "# Credentials in a file .env\n",
    "ACCESS_KEY=os.environ.get(\"ACCESS_KEY\")\n",
    "SECRET_KEY = os.environ.get(\"SECRET_KEY\")\n",
    "\n",
    "# # Uncomment to use this part\n",
    "# # Create a Boto3 session\n",
    "# session = boto3.Session(\n",
    "#     aws_access_key_id=ACCESS_KEY,\n",
    "#     aws_secret_access_key=SECRET_KEY,\n",
    "#     region_name=\"sa-east-1\"\n",
    "# )\n",
    "\n",
    "# session= None # optional, don't need to explicit close the session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1</th>\n",
       "      <th>Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.99991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>796.0</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.99987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.99998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLIENTNUM     Attrition_Flag  Customer_Age Gender  Dependent_count  \\\n",
       "0  768805383  Existing Customer            45      M                3   \n",
       "1  818770008  Existing Customer            49      F                5   \n",
       "2  713982108  Existing Customer            51      M                3   \n",
       "3  769911858  Existing Customer            40      F                4   \n",
       "4  709106358  Existing Customer            40      M                3   \n",
       "\n",
       "  Education_Level Marital_Status Income_Category Card_Category  \\\n",
       "0     High School        Married     $60K - $80K          Blue   \n",
       "1        Graduate         Single  Less than $40K          Blue   \n",
       "2        Graduate        Married    $80K - $120K          Blue   \n",
       "3     High School        Unknown  Less than $40K          Blue   \n",
       "4      Uneducated        Married     $60K - $80K          Blue   \n",
       "\n",
       "   Months_on_book  ...  Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  \\\n",
       "0              39  ...       12691.0                  777          11914.0   \n",
       "1              44  ...        8256.0                  864           7392.0   \n",
       "2              36  ...        3418.0                    0           3418.0   \n",
       "3              34  ...        3313.0                 2517            796.0   \n",
       "4              21  ...        4716.0                    0           4716.0   \n",
       "\n",
       "   Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "0                 1.335             1144              42                1.625   \n",
       "1                 1.541             1291              33                3.714   \n",
       "2                 2.594             1887              20                2.333   \n",
       "3                 1.405             1171              20                2.333   \n",
       "4                 2.175              816              28                2.500   \n",
       "\n",
       "   Avg_Utilization_Ratio  \\\n",
       "0                  0.061   \n",
       "1                  0.105   \n",
       "2                  0.000   \n",
       "3                  0.760   \n",
       "4                  0.000   \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  \\\n",
       "0                                           0.000093                                                                                    \n",
       "1                                           0.000057                                                                                    \n",
       "2                                           0.000021                                                                                    \n",
       "3                                           0.000134                                                                                    \n",
       "4                                           0.000022                                                                                    \n",
       "\n",
       "   Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  \n",
       "0                                            0.99991                                                                                   \n",
       "1                                            0.99994                                                                                   \n",
       "2                                            0.99998                                                                                   \n",
       "3                                            0.99987                                                                                   \n",
       "4                                            0.99998                                                                                   \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "df = pd.read_csv(\"../Data/data_for_da/BankChurners.csv\")\n",
    "\n",
    "# show first 5 \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            _default\n",
      "1  {'title': 'NumüÖ±er One', 'thumbnail': {'thumbna...\n",
      "2  {'title': 'Got ‚Äòem', 'thumbnail': {'thumbnail'...\n",
      "3  {'title': '50-0', 'thumbnail': {'thumbnail': '...\n",
      "4  {'title': 'Allow', 'thumbnail': {'thumbnail': ...\n",
      "5  {'title': '*mild concern*', 'thumbnail': {'thu...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 'NumüÖ±er One',\n",
       " 'thumbnail': {'thumbnail': 'https://b.thumbs.redditmedia.com/FAS_fWvrpmzuPN6Rh67I9ahmovzoe-titgZNilnewpk.jpg',\n",
       "  'height': 121,\n",
       "  'width': 140},\n",
       " 'created_utc': 1502621109.0,\n",
       " 'author': 'DrarenThiralas',\n",
       " 'id': '6tehbc',\n",
       " 'ups': 87082,\n",
       " 'downs': 0,\n",
       " 'media': 'https://i.redd.it/7wgs4dkiihfz.png'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "df = pd.read_json(\"../Data/data_for_da/db_json_example.json\")\n",
    "\n",
    "# show first 5 \n",
    "print(df.head())\n",
    "# Checking one item\n",
    "df['_default'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"<excel file path>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interacting with web APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# site you want to access\n",
    "url = \"<site_url>\"\n",
    "\n",
    "# # response\n",
    "# response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Cleaning and Tansforming**\n",
    "\n",
    "* **Remove major errors, duplicates, and outliers**\n",
    "* **String manipulation** - Correct the string data (lower, fixing typos or layout issues, capitalize)\n",
    "* **Transforming the necessary fields** - Transform the data, split fields, concatenate fields, transform fields, substitute NaN values or place than when necessary ...\n",
    "* **Filling missing gaps** - utilize *FFNN*, forward fill, mean values, median values, subtitute a string field with a similary field, backward fill, interpolation, multiple imputation,K-Nearest Neighbors Imputations (KNNImputer), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To use this cell just -->   ctrl + /\n",
    "\n",
    "# import re # for regex cleaning\n",
    "\n",
    "# # Commads to clean data \n",
    "\n",
    "# # Drop NA values\n",
    "# df = df.dropna() # Save to a new df, same df or save inplace\n",
    "# # The same as \n",
    "# df[df.notnull()]\n",
    "\n",
    "# # Drop columms\n",
    "# df = df.drop(columns = \"<Column_you_dont_want>\")\n",
    "\n",
    "# # Fill NA \n",
    "# new_df = df.fillna() # complete with args you want ffll, bbll ...\n",
    "# df.fillna('')\n",
    "\n",
    "\n",
    "# # Check if theres is null\n",
    "# df.isnull()\n",
    "\n",
    "# # Check if not null\n",
    "# df.notnull()\n",
    "\n",
    "# # Removing duplicates\n",
    "# df.drop_duplicates()\n",
    "# df.drop_duplicates([\"<some_key>\"])\n",
    "\n",
    "# # Lowering case string\n",
    "# lower = df['<field_name>'].str.lower()\n",
    "\n",
    "# # endswith / startswitch / contains\n",
    "# df.str.endswith('<pattern_value>')\n",
    "# df.str.startswith('<pattern_value>')\n",
    "# df.str.contains('<pattern_value>')\n",
    "\n",
    "# # join method\n",
    "# # find method\n",
    "\n",
    "# # Using map function to map values\n",
    "# df['<field_name>'].map(lambda x: <dictionary_name>[x.lower()])\n",
    "\n",
    "# # Replace values\n",
    "# df['<field_name>'] = df['<field_name>'].replace({\"<value_1>\": \"<new_value_1>\",\"<value_2>\": \"<new_value_2>\"})\n",
    "# df.replace(\"<value>\", \"<new_value>\")\n",
    "# df['<phone_number>'] = df['<phone_number>'].str.replace('[^a-zA-Z0-9]','') # regex style\n",
    "# df['<phone_number>'].apply(lambda x: str(x))\n",
    "# df['<phone_number>'].apply(lambda x: x[:3]+\"-\"+x[3:6]+\"-\")\n",
    "\n",
    "# # Split string data\n",
    "# df[['<new_collumn_name_1>','<new_collumn_name_2>']] = df['<field_name>'].str.split(\"<symbol_you_want_to_spli>\", expand=True)\n",
    "# df[['<new_collumn_name_1>','<new_collumn_name_2>']] = df['<field_name>'].str.split(\"<symbol_you_want_to_spli>\",n=1, expand=True)\n",
    "\n",
    "# # Striping\n",
    "# df['<field_name>'] = df['<field_name>'].str.lstrip(\"<string_you_want_to_remove>\")\n",
    "# df['<field_name>'] = df['<field_name>'].str.rstrip(\"<string_you_want_to_remove>\")\n",
    "# df['<field_name>'] = df['<field_name>'].str.strip(\"<string_you_want_to_remove>\")\n",
    "\n",
    "# # Regex methods usinf re or str\n",
    "# # .findall()\n",
    "# # .finditer()\n",
    "# # .match()\n",
    "# # .search()\n",
    "# # .split()\n",
    "# # .sub\n",
    "# # .subn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports for transformation and preprocessing data (scikit-learn library)\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, OneHotEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some links for data transformation\n",
    "https://scikit-learn.org/stable/data_transforms.html\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.merge.html\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To use this cell just -->   ctrl + /\n",
    "\n",
    "# # Transforming data\n",
    "# # Few of the tansformations \n",
    "\n",
    "# # Changing data types\n",
    "# df.astype({'<column_you_want_to_change>': '<type_you_want'})\n",
    "\n",
    "\n",
    "# # New column/Field\n",
    "# df['<new_col_name>'] = df['<col_1>'] * 10\n",
    "# df['<new_col_name>'] = 1\n",
    "# df[['<new_col_name>', '<new_col_name>']] = 1\n",
    "# df = df.assign()\n",
    "\n",
    "\n",
    "# # Encoding/ One-hot-encode (transformin categorical / string/ tokens variables to numerical)\n",
    "# dummies = pd.get_dummies(data=\"<df[\"column\"]>\", prefix=\"<String to append DataFrame column names>\", dtype=\"<type_variable(int,float,...)\")\n",
    "# df_dummies = pd.concat([df, dummies], axis=1)\n",
    "# # or\n",
    "# df_dummies = df.join(dummies)\n",
    "# df = pd.get_dummies(df, columns=['<coloumn_name)'])\n",
    "# # OneHotEncoder() from Sklearn library\n",
    "\n",
    "\n",
    "# # Data binning\n",
    "# # Continuos data can be separated in bins\n",
    "# bins = [10, 30, 45, 60, 100]\n",
    "# new_df[\"<new_column>\"] = pd.cut(data=df['<column>'], bins=bins, precision=2)\n",
    "# # bins with quantils\n",
    "# new_data = pd.qcut(data=df['<column>'], q=<number_of_quantiles>)\n",
    "# new_data = pd.qcut(data=df['<column>'], q=<number_of_quantiles>, labels=[\"<label_1>\", \"<label_2>\",\"<label_3>\"])\n",
    "\n",
    "\n",
    "# # Data Scaling\n",
    "# # Standardization, or mean removal and variance scaling\n",
    "\n",
    "\n",
    "# # Define the scaler\n",
    "# # Standardization\n",
    "# scaler = preprocessing.StandardScalar()\n",
    "# # Scaling features to a range (MinMaxScaler()[0, 1] or MaxAbsScaler()[-1, 1])\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "# # transform data\n",
    "# scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "# # Normalization - is the process of scaling individual samples to have unit norm.\n",
    "# X_normalized = preprocessing.normalize(X, norm='l2') # norms = l1, l2, or max\n",
    "# normalizer = preprocessing.Normalizer()\n",
    "# normalized = normalizer.fit_transform(data)\n",
    "\n",
    "\n",
    "# # Conditional Filtering data\n",
    "\n",
    "# # Filtering columns\n",
    "# new_df = df[['<col_1>', '<col_2>']]\n",
    "\n",
    "# # Filtering rows with conditions\n",
    "# cond_1 = df[df['<col_1>'] > 35] # Return the rows for which the col <col_1> are greater than 35\n",
    "# # Could be >, <, ==, !=, <=,...\n",
    "# # Conditional expression\n",
    "# cond_2 = df[df['<col_1>'].isin('<list_values>')]\n",
    "# cond_3 = df[cond_1 = df[(df['<col_1>'] == 2) | (df['<col_1>'] ==3)] # Each condition must be surrounded by parentheses (),  | - or, & - and.\n",
    "\n",
    "# Selecting a specific rows and columns from a DataFrama\n",
    "# df.loc[df['<col>'] > 6, ['<name_col_you_want>']]\n",
    "# df.loc[(df['<col_1>'] > 1) & (df['<col_2>'] < 8)]\n",
    "# Setting values\n",
    "# df.loc[['<row_1>', '<row_2>'], ['<condition_you_want>']] = 50 # Set value for all items matching the list of labels\n",
    "\n",
    "# # Data Modification inside Dataframe\n",
    "# df = df.apply('<func_name>', axis=0)\n",
    "\n",
    "\n",
    "# # Data Aggregation\n",
    "# df.groupby('<col_name>').agg('min') # Aggregation is for each column.\n",
    "# df.groupby('<col_name>').agg(lambda x: sum(x) + 2) # Example using function.\n",
    "# df = df.agg(func=['<func_name>','<func_name>'], axis=0)\n",
    "# df.agg({'<col_name>' : ['sum', 'min'], '<col_name>' : ['min', 'max']}) # Different aggregations per column.\n",
    "\n",
    "\n",
    "\n",
    "# # Joining data from different sources\n",
    "# # Merge in dataframe or join in relational databases like SQL\n",
    "# # There are a lot of ways on how to join different data, some examples are:\n",
    "\n",
    "# new_df = pd.merge(left='<df1>', \n",
    "#                 right='<df2>',\n",
    "#                 how='<method_of_merger>', # can be ['inner', 'left', 'right', 'outer', 'cross',...]\n",
    "#                 on='<col_or_index_to_join_on>',\n",
    "#                 suffixes='<tuple_of_str_for_name>')\n",
    "\n",
    "# new_df = pd.merge(left='<df1>', \n",
    "#                 right='<df2>',\n",
    "#                 how='<method_of_merger>',\n",
    "#                 left_on='<col_or_index_to_join_on_in_the_left_DataFrame>')\n",
    "\n",
    "# new_df = <df1>'.merge('<df2>', how='<method_of_merger>', on='<col_or_index_to_join_on>')\n",
    "\n",
    "\n",
    "# # Concatenation of data\n",
    "# new_concat_df = pd.concat(objs=\"<['<df1>','<df2>','<df3>']>\",\n",
    "#                           axis='<0>-rows_or_<1>_column', \n",
    "#                           ignore_index='<bool>',) # defaul False. If True, do not use index values along concat axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods.\n",
    "\n",
    "\n",
    "### **4. Analyze**\n",
    "* Sort and filter data\n",
    "* Identify patterns and draw conclusions\n",
    "* Make predictions and recommendations\n",
    "* Make data-driven decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining basic information about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "df = pd.read_csv(\"../Data/data_for_da/BankChurners.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10127 entries, 0 to 10126\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                                                                                                              Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                              --------------  -----  \n",
      " 0   CLIENTNUM                                                                                                                           10127 non-null  int64  \n",
      " 1   Attrition_Flag                                                                                                                      10127 non-null  object \n",
      " 2   Customer_Age                                                                                                                        10127 non-null  int64  \n",
      " 3   Gender                                                                                                                              10127 non-null  object \n",
      " 4   Dependent_count                                                                                                                     10127 non-null  int64  \n",
      " 5   Education_Level                                                                                                                     10127 non-null  object \n",
      " 6   Marital_Status                                                                                                                      10127 non-null  object \n",
      " 7   Income_Category                                                                                                                     10127 non-null  object \n",
      " 8   Card_Category                                                                                                                       10127 non-null  object \n",
      " 9   Months_on_book                                                                                                                      10127 non-null  int64  \n",
      " 10  Total_Relationship_Count                                                                                                            10127 non-null  int64  \n",
      " 11  Months_Inactive_12_mon                                                                                                              10127 non-null  int64  \n",
      " 12  Contacts_Count_12_mon                                                                                                               10127 non-null  int64  \n",
      " 13  Credit_Limit                                                                                                                        10127 non-null  float64\n",
      " 14  Total_Revolving_Bal                                                                                                                 10127 non-null  int64  \n",
      " 15  Avg_Open_To_Buy                                                                                                                     10127 non-null  float64\n",
      " 16  Total_Amt_Chng_Q4_Q1                                                                                                                10127 non-null  float64\n",
      " 17  Total_Trans_Amt                                                                                                                     10127 non-null  int64  \n",
      " 18  Total_Trans_Ct                                                                                                                      10127 non-null  int64  \n",
      " 19  Total_Ct_Chng_Q4_Q1                                                                                                                 10127 non-null  float64\n",
      " 20  Avg_Utilization_Ratio                                                                                                               10127 non-null  float64\n",
      " 21  Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1  10127 non-null  float64\n",
      " 22  Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2  10127 non-null  float64\n",
      "dtypes: float64(7), int64(10), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 \n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".workvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
